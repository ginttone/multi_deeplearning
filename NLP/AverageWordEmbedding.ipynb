{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AverageWordEmbedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmpp/KM8z7O3TnY1m08e93",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ginttone/multi_deeplearning/blob/master/NLP/AverageWordEmbedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk_BqR588pgH"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMxZL1Od9DRA",
        "outputId": "4f733732-30fe-4d61-a80b-f198b0633aa1"
      },
      "source": [
        "vocab_size = 2000\n",
        "(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words=vocab_size)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000,), (25000,), (25000,), (25000,))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY2YQw8K9pko",
        "outputId": "8ffe92f2-7e5d-4e2b-8b94-de7daf1d5438"
      },
      "source": [
        "print(x_train[1])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 2, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 2, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 2, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 656, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvYQZX7p91iG"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS2aGZBF-DRY",
        "outputId": "106f6525-6c0b-4d6f-8bc9-359a6765a8ae"
      },
      "source": [
        "len(x_train[1]),len(x_train[200])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(189, 160)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gStbn5E-bzW"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbh1IAhm-g4a"
      },
      "source": [
        "X_train = pad_sequences(x_train, maxlen=300)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBTeXjW--t8b"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjcMQnLe-5hW"
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spio28-q_0AH",
        "outputId": "b843b17e-25a1-487d-aa07-26712bbe97f8"
      },
      "source": [
        "import numpy as np\n",
        "np.unique(y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INCMMsG1_dWb"
      },
      "source": [
        "tf.keras.layers.Embedding(보케블러리 사이즈, 차원 사이즈 , 랭스=패드시퀀스 값)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwIoo6ov_Ezq"
      },
      "source": [
        "model.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=50, input_length=300))\n",
        "model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
        "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vnOQ44jBDlk",
        "outputId": "7530416e-8723-4302-fd51-a72fb10af069"
      },
      "source": [
        "hist = model.fit(X_train,y_train, epochs=10, batch_size=128, validation_split=0.2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'dense/kernel:0', 'dense/bias:0'] when minimizing the loss.\n",
            "157/157 [==============================] - 2s 5ms/step - loss: 0.6932 - val_loss: 0.6932\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6933 - val_loss: 0.6935\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6932 - val_loss: 0.6939\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6933 - val_loss: 0.6935\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6932 - val_loss: 0.6933\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6933 - val_loss: 0.6933\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6932 - val_loss: 0.6931\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6932 - val_loss: 0.6931\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6932 - val_loss: 0.6931\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6932 - val_loss: 0.6931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o8Xhx9BBTRI",
        "outputId": "2dc4209f-c73e-45a1-b373-414fa81f32b7"
      },
      "source": [
        "model.predict(X_train[5:6]) # loss: 0.6932 - val_loss: 0.6931"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49546075]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vrogADKCZlO"
      },
      "source": [
        "## [Callback EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)\n",
        "\n",
        "tf.keras.callbacks.EarlyStopping\n",
        "\n",
        "교육 중 합당하게 도달하거나 튀면 에포크만큼 진행하지 않고 멈춤\n",
        "\n",
        "벨리데이션 로스가 올라가기 직전에서 (과적합막음) 멈춤\n",
        "```\n",
        "tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', min_delta=0, patience=0, verbose=0,\n",
        "    mode='auto', baseline=None, restore_best_weights=False\n",
        ")\n",
        "```\n",
        "\n",
        "모니터(monitor=) 하는 값이 (patience)의 갯수 만큼 모드(mode)에 맞게 동작햇으면 멈춰라"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2c-g-1JBdXZ",
        "outputId": "77a3925e-3cc4-490f-ec4d-9055024bb6de"
      },
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, mode ='min', verbose=1)\n",
        "es"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.EarlyStopping at 0x7fa89ce1a810>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSlczbh6EIrI",
        "outputId": "844a5d60-4845-44a7-8622-b9461d625b86"
      },
      "source": [
        "hist = model.fit(X_train,y_train, epochs=20, batch_size=128, validation_split=0.2, callbacks=[es])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6932 - val_loss: 0.6932\n",
            "Epoch 2/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6932 - val_loss: 0.6931\n",
            "Epoch 3/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6932 - val_loss: 0.6936\n",
            "Epoch 4/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6932 - val_loss: 0.6932\n",
            "Epoch 5/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6932 - val_loss: 0.6933\n",
            "Epoch 6/20\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6933 - val_loss: 0.6932\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKUix7FJEZyI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}